{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Bayesian Statistics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LEARNING OBJECTIVES\n",
    "\n",
    "After this lesson, you will be able to:\n",
    "\n",
    "- Derive and explain Bayess theorem\n",
    "- Explain the components of the Bayesian \"world view\" -- posterior, prior, likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frequentist vs. Bayesian\n",
    "\n",
    "**Frequentists** believe the \"true\" distribution is fixed (and not known). We can infer more more about this \"true\" distribution by engaging in sampling, testing for effects, and studying relevant parameters of the population.\n",
    "\n",
    "**Bayesians** believe that data informs us about the distribution, and as we receive more data our view of the distribution can be updated, further confirming or denying our previous beliefs (but never in certainty).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Interpretations of probability\n",
    "\n",
    "**FREQUENTIST PROBABILITY** \n",
    "\n",
    "Probability is the true number of \"successes\" or \"positive ocurrences\" measured across the hypothetical infinite number of samples/events/trials:\n",
    "\n",
    "### $$p = \\lim_{n \\to +\\infty} \\frac{k}{n}$$\n",
    "\n",
    "where:\n",
    "$p$ is the probability of an occurance.\n",
    "$k$ is the number of occurances.\n",
    "$n$ is the number of events.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A review of (Bayesian) terminology \n",
    "\n",
    "**Probability**: a number between 0 and 1, inclusive, representing \"a degree of belief in a fact or prediction\".\n",
    "\n",
    "**Conditional probability**: a probability of something given some background information; the conditional probability of A given that B is true is written $P\\left(\\;A\\;|\\;B\\;\\right)$\n",
    "\n",
    "**Marginal probability**: the (non-conditional) probability of something occurring, $P\\left(\\;B\\;\\right)$\n",
    "\n",
    "**Joint probability**: the probability that two things are true; joint probability of A and B is written $P\\left(\\;A\\;\\cap\\;B\\right)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**BAYESIAN PROBABILITY**\n",
    "\n",
    "Probability is a representation of our uncertainty given what we know and believe to be true. Given a number of observed positive occurances over a number of events *and our prior belief about the true probability of positive occurances,* what is the *distribution of the true probability*?\n",
    "\n",
    "### $$P\\left(\\;true\\;|\\;observed\\;\\right) = \\frac{P\\left(\\;observed\\;|\\;true\\;\\right)}{P(\\;observed\\;)} P\\left(\\;true\\;\\right)$$\n",
    "\n",
    "where:\n",
    "\n",
    "$P\\left(\\;true\\;|\\;observed\\;\\right)$ is the **posterior probability** or **conditional probability**. This is the probability of an occurence given what we observed.\n",
    "\n",
    "$P\\left(\\;observed\\;|\\;true\\;\\right)$ is the **likelihood,** which is the probability of what we observed  given our prior belief about the probability of occurance. \n",
    "\n",
    "${P(\\;observed\\;)}$ is the **marginal probability** of the observed data. \n",
    "\n",
    "$P\\left(\\;true\\;\\right)$ is the **prior probability** belief. It is what you thought the probability was before observing the events.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' theorem\n",
    "\n",
    "Some of you might recognize the above formula as Bayes' theorem. Typically Bayes' theorem is written:\n",
    "\n",
    "### $$P\\left(\\;A\\;|\\;B\\;\\right) = \\frac{P\\left(\\;B\\;|\\;A\\;\\right)P\\left(\\;A\\;\\right)}{P(\\;B\\;)}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$A$ and $B$ are anything that take probabilities (which is essentially everything). $P(B|A)$ and $P(A|B)$ are the probabilities of $B$ conditional on $A$ and vice versa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is just another way of writing:\n",
    "\n",
    "### $$P\\left(\\;A\\;\\right)P\\left(\\;B\\;|\\;A\\;\\right) = P\\left(\\;B\\;\\right)P\\left(\\;A\\;|\\;B\\;\\right)$$\n",
    "\n",
    "Which is derived from the fact that:\n",
    "\n",
    "### $$P\\left(\\;A\\;\\cap\\;B\\right) = P\\left(\\;A\\;\\right)P\\left(\\;B\\;|\\;A\\;\\right) = P\\left(\\;B\\;\\right)P\\left(\\;A\\;|\\;B\\;\\right)$$\n",
    "\n",
    "Where $P\\left(\\;A\\;\\cap\\;B\\right)$ is the probability of $A$ *and* $B$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Denominator of Bayes' theorem: the \"total probability\"\n",
    "\n",
    "![](./assets/images/output_27_0.png)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the picture, each $A_1,..., A_5$ includes a piece of the center oval. In this example the oval represents $B$.\n",
    "\n",
    "Basic probability defines the following relation: $$P(A|B) = \\frac{ A \\cap B }{B}$$ \n",
    "\n",
    "Intuitively, the relation indicates that $P(A|B)$ is a ratio of the part of A that is common with B, *over the entirety of $B$*. \n",
    "\n",
    "Therefore, **the total probability can be thought of as the exhaustive sum of all probabilities on sets that share elements with B**. This equals simply the probability of B in our set of events.\n",
    "\n",
    "So what is the purpose of the total probability with respect to the rest of Bayes formula? **In essence, it \"normalizes\" the numerator into a quantity between 0 and 1,** ensuring the left side of the formula is a probability.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solving probability using Bayes' theorem is easy when you know $P(B)$\n",
    "\n",
    "Let's say we have two coins. Coin **FAIR** and coin **RIGGED**\n",
    "\n",
    "    coin FAIR has a 50% chance of flipping heads.\n",
    "    coin RIGGED has 99% chance of flipping heads.\n",
    "    \n",
    "Your friend chooses one of the two coins at random. He flips the coin and gets heads. \n",
    "\n",
    "What is the probability that the coin flipped was **FAIR**?\n",
    "\n",
    "> Check: what are the point probabilities for the prior, likelihood, and marginal probability fo the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.335570469799 0.335570469799\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Our hypothesis is our belief that the coin flipped was fair before we saw the outcome. \n",
    "# 0.5 since he chose at random.\n",
    "hypothesis_fair = 0.5\n",
    "\n",
    "# probability that we would get heads given our hypothesis was true, that the coin is the fair one:\n",
    "prob_flip_given_fair = 0.5\n",
    "\n",
    "# total probability of getting heads:\n",
    "prob_heads = (149./200.)\n",
    "\n",
    "# solve for the probability our hypothesis is true given the flip:\n",
    "hypothesis_true = (prob_flip_given_fair * hypothesis_fair) / prob_heads\n",
    "\n",
    "\n",
    "print hypothesis_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Bayes' theorem in the context of statistical modeling\n",
    "\n",
    "We can also interpret the equations above in the context of statistical modeling, which we've been doing tons of in this class:\n",
    "\n",
    "### $$P\\left(\\;model\\;|\\;data\\;\\right) = \\frac{P\\left(\\;data\\;|\\;model\\;\\right)}{P(\\;data\\;)} P\\left(\\;model\\;\\right)$$\n",
    "\n",
    "Or in plain english:\n",
    "\n",
    "**What is the probability of our model being true, given the data we have? This depends on the likelihood of the observed data given our model and the data itself, as well as our prior belief that this model is true.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computational solutions with Bayes' theorem\n",
    "\n",
    "Consider two shoppers' baskets in an e-commerce store\n",
    "\n",
    "Basket 1 has 30 cans of seltzer and 10 cans of V8. Basket 2 has 20 cans of each\n",
    "\n",
    "You picked one basket at random and selected can, which was seltzer. What's the probability it came from basket 1?\n",
    "\n",
    "> Check: solve this manually with point estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is a very simple case, but we can start to employ **prior distributions**, giving us **posterior distributions**, instead of point probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "hypo_dist = {'Basket1': .5, 'Basket2': .5} # Priors\n",
    "likelihood_dist = {'Basket1': .75, 'Basket2': .5} # Likelihood\n",
    "marginal_prob = 5/8.0 # Our normalizing constant, the marginal probability\n",
    "\n",
    "print (hypo_dist['Basket1'] * likelihood_dist['Basket1']) / marginal_prob\n",
    "print (hypo_dist['Basket2'] * likelihood_dist['Basket2']) / marginal_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We more often use functions to calculate distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01699891,  0.09155492])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.uniform.rvs(0,1, size = 2) # Uniform likelihood of picking out a seltzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Independent practice: the train problem\n",
    "\n",
    "\"A railroad numbers its locomotives in order 1...N. You see a locomotive with the number 60. Estimate how many locomotives the railroad has.\" What's the prior? What's the likelihood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The prior is what we knew (or will assume) about N before our observation of data.\n",
    "\n",
    "The likelihood is the probability of seeing the data for any given value of N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How can you write a likelihood function for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References and sources modeled off of:\n",
    "\n",
    "http://ipython-books.github.io/featured-07/\n",
    "\n",
    "http://stats.stackexchange.com/questions/31867/bayesian-vs-frequentist-interpretations-of-probability\n",
    "\n",
    "http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/\n",
    "\n",
    "https://simple.wikipedia.org/wiki/Bayes%27_theorem\n",
    "\n",
    "https://en.wikipedia.org/wiki/Central_limit_theorem\n",
    "\n",
    "http://www.cogsci.ucsd.edu/classes/SP07/COGS14/NOTES/binomial_ztest.pdf\n",
    "\n",
    "https://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors\n",
    "\n",
    "https://arbital.com/p/bayes_rule/?l=1zq\n",
    "\n",
    "https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/\n",
    "\n",
    "http://www.yudkowsky.net/rational/bayes/\n",
    "\n",
    "http://people.stern.nyu.edu/wgreene/MathStat/Notes-2-BayesianStatistics.pdf\n",
    "\n",
    "http://stats.stackexchange.com/questions/58564/help-me-understand-bayesian-prior-and-posterior-distributions\n",
    "\n",
    "http://pages.uoregon.edu/cfulton/posts/bernoulli_trials_bayesian.html\n",
    "\n",
    "http://chrisstrelioff.ws/sandbox/2014/12/11/inferring_probabilities_with_a_beta_prior_a_third_example_of_bayesian_calculations.html\n",
    "\n",
    "https://www.chrisstucchio.com/blog/2013/magic_of_conjugate_priors.html\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
