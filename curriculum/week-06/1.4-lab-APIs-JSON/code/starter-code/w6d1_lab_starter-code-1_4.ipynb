{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs Lab\n",
    "In this lab we will practice using APIs to retrieve and store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports at the top\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Get Data From Sheetsu\n",
    "\n",
    "[Sheetsu](https://sheetsu.com/) is an online service that allows you to access any Google spreadsheet from an API. This can be a very handy way to share a dataset with colleagues as well as to create a mini centralized data storage, that is simpler to edit than a database.\n",
    "\n",
    "A Google Spreadsheet with wine data can be found [here](https://docs.google.com/a/generalassemb.ly/spreadsheets/d/1JWRwDnwIMLgvPqNMdJLmAJgzvz0K3zAUc6jev3ci1c8/edit?usp=sharing).\n",
    "\n",
    "You can access it through the Sheetsu API at this endpoint: https://sheetsu.com/apis/v1.0/cc9420722ae4. [Here](https://sheetsu.com/docs/beta) is Sheetsu's documentation.\n",
    "\n",
    "\n",
    "Questions:\n",
    "\n",
    "1. Use the requests library to access the document. Inspect the response text. What kind of data is it?\n",
    "2. Check the status code of the response object. What code is it?\n",
    "3. Use the appropriate libraries and read functions to read the response into a Pandas Dataframe\n",
    "4. Once you've imported the data into a dataframe, check the value of the 5th line: what's the price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answers:\n",
    "    1. A JSON string.\n",
    "    2. 200\n",
    "    3. Options inlucde: pd.read_json; json.loads + pd.Dataframe\n",
    "    4. 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Post Data to Sheetsu\n",
    "Now that we've learned how to read data, it'd be great if we could also write data. For this we will need to use a _POST_ request.\n",
    "\n",
    "1. Use the post command to add the following data to the spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_data = {\n",
    "'Grape' : ''\n",
    ", 'Name' : 'My wonderful wine'\n",
    ", 'Color' : 'R'\n",
    ", 'Country' : 'US'\n",
    ", 'Region' : 'Sonoma'\n",
    ", 'Vinyard' : ''\n",
    ", 'Score' : '10'\n",
    ", 'Consumed In' : '2015'\n",
    ", 'Vintage' : '1973'\n",
    ", 'Price' : '200'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What status did you get? How can you check that you actually added the data correctly?\n",
    "- In this exercise, your classmates are adding data to the same spreadsheet. What happens because of this? Is it a problem? How could you mitigate it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Data munging\n",
    "\n",
    "Get back to the dataframe you've created in the beginning. Let's do some data munging:\n",
    "\n",
    "1. Search for missing data\n",
    "    - Is there any missing data? How do you deal with it?\n",
    "    - Is there any data you can just remove?\n",
    "    - Are the data types appropriate?\n",
    "- Summarize the data \n",
    "    - Try using describe, min, max, mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Feature Extraction\n",
    "\n",
    "We would like to use a regression tree to predict the score of a wine. In order to do that, we first need to select and engineer appropriate features.\n",
    "\n",
    "- Set the target to be the Score column, drop the rows with no score\n",
    "- Use pd.get_dummies to create dummy features for all the text columns\n",
    "- Fill the nan values in the numerical columns, using an appropriate method\n",
    "- Train a Decision tree regressor on the Score, using a train test split:\n",
    "        X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "- Plot the test values, the predicted values and the residuals\n",
    "- Calculate R^2 score\n",
    "- Discuss your findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: IMDB Movies\n",
    "\n",
    "Sometimes an API doesn't provide all the information we would like to get and we need to be creative.\n",
    "Here we will use a combination of scraping and API calls to investigate the ratings and gross earnings of famous movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.a Get top movies\n",
    "\n",
    "The Internet Movie Database contains data about movies. Unfortunately it does not have a public API.\n",
    "\n",
    "The page http://www.imdb.com/chart/top contains the list of the top 250 movies of all times. Retrieve the page using the requests library and then parse the html to obtain a list of the `movie_ids` for these movies. You can parse it with regular expression or using a library like `BeautifulSoup`.\n",
    "\n",
    "**Hint:** movie_ids look like this: `tt2582802`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.b Get top movies data\n",
    "\n",
    "Although the Internet Movie Database does not have a public API, an open API exists at http://www.omdbapi.com.\n",
    "\n",
    "Use this API to retrieve information about each of the 250 movies you have extracted in the previous step.\n",
    "- Check the documentation of omdbapi.com to learn how to request movie data by id\n",
    "- Define a function that returns a python object with all the information for a given id\n",
    "- Iterate on all the IDs and store the results in a list of such objects\n",
    "- Create a Pandas Dataframe from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.c Get gross data\n",
    "\n",
    "The OMDB API is great, but it does not provide information about Gross Revenue of the movie. We'll revert back to scraping for this.\n",
    "\n",
    "- Write a function that retrieves the gross revenue from the entry page at imdb.com\n",
    "- The function should handle the exception of when the page doesn't report gross revenue\n",
    "- Retrieve the gross revenue for each movie and store it in a separate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.d Data munging\n",
    "\n",
    "- Now that you have movie information and gross revenue information, let's clean the two datasets.\n",
    "- Check if there are null values. Be careful they may appear to be valid strings.\n",
    "- Convert the columns to the appropriate formats. In particular handle:\n",
    "    - Released\n",
    "    - Runtime\n",
    "    - year\n",
    "    - imdbRating\n",
    "    - imdbVotes\n",
    "- Merge the data from the two datasets into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.d Text vectorization\n",
    "\n",
    "There are several columns in the data that contain a comma separated list of items, for example the Genre column and the Actors column. Let's transform those to binary columns using the count vectorizer from scikit learn.\n",
    "\n",
    "Append these columns to the merged dataframe.\n",
    "\n",
    "**Hint:** In order to get the actors name right, you'll have to set the `token_pattern` parameter in `CountVectorizer` to u'(?u)\\\\w+\\.?\\\\w?\\.? \\\\w+'. Can you see why? How does this differ from the default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "\n",
    "- What are the top 10 grossing movies?\n",
    "- Who are the 10 actors that appear in the most movies?\n",
    "- What's the average grossing of the movies in which each of these actors appear?\n",
    "- What genre is the oldest movie?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
